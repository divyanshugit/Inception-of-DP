# Inception of Differential Privacy

## Relevant Papers

### Differential Privacy: Background and Mathematics
- [Differential Privacy](https://www.comp.nus.edu.sg/~tankl/cs5322/readings/dwork.pdf)
- [The Algorithmic Foundations of Differential Privacy - chapter 2, basic terms (including (ε, δ)-DP), chapter 3.3 Laplace Mechanism](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf)
  
### Differential Private Stochastic Gradient Descent (DPSGD) and its Privacy Analysis
- [The Algorithmic Foundations of Differential Privacy - Appendix A, the Gaussian Mechanism](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf)
- [Deep Learning with Differential Privacy](https://dl.acm.org/doi/pdf/10.1145/2976749.2978318)
  
### Rényi Differential Privacy and its application for Subsampled Gaussian Mechanisms
- [Rényi Differential Privacy](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8049725&casa_token=49x1-mFlfCAAAAAA:80zWk1Ugi1NGTI7-FB43fd5_8IxalxnQr_BXOtjdmVbZjW-SYJfZE20Tko6Ai5FQeU35rLPc)
- [Subsampled Rényi Differential Privacy and Analytical Moments Accountant](https://proceedings.mlr.press/v89/wang19b/wang19b.pdf)
- [Rényi Differential Privacy of the Sampled Gaussian Mechanism](https://arxiv.org/pdf/1908.10530.pdf)

### The Private Aggregation of Teacher Ensembles (PATE) for Machine Learning with Privacy Guarantees
- [Semi-supervised knowledge transfer for deep learning from private training data - algorithm and particular emphasis on Section 3.3 Data dependent Privacy Analysis](https://arxiv.org/pdf/1610.05755.pdf)
- [Scalable private learning with pate](https://arxiv.org/pdf/1802.08908.pdf)
  
### Heterogenous/Individualized Differential Privacy
- [Individualized PATE: Differentially Private Machine Learning with Individual Privacy Guarantees](https://arxiv.org/pdf/2202.10517.pdf)
- [Have it your way: Individualized Privacy Assignment for DP-SGD](https://arxiv.org/pdf/2202.10517.pdf)
- [Individual Privacy Accounting via a Rényi Filter](https://proceedings.neurips.cc/paper/2021/file/ec7f346604f518906d35ef0492709f78-Paper.pdf)
  
### Privacy Auditing in Blackbox-Access
- [Auditing differentially private machine learning: How private is private sgd?](https://proceedings.neurips.cc/paper/2020/file/fc4ddc15f9f4b4b06ef7844d6bb53abf-Paper.pdf)
- [Debugging differential privacy: A case study for privacy auditing](https://arxiv.org/pdf/2202.12219.pdf)
- [Tight Auditing of Differentially Private Machine Learning](https://arxiv.org/pdf/2302.07956.pdf)
  
### Differential Privacy for Large Language Models
- [Large Language Models Can Be Strong Differentially Private Learners](https://arxiv.org/pdf/2110.05679.pdf)
- [Differentially Private Fine-tuning of Language Models](https://arxiv.org/pdf/2110.06500.pdf)
- [Flocks of Stochastic Parrots: Differentially Private Prompt Learning for Large Language Models](https://arxiv.org/pdf/2305.15594.pdf)

### Memorization
- [Does learning require memorization? a short tale about a long tail](https://arxiv.org/pdf/1906.05271.pdf)
- [What neural networks memorize and why: Discovering the long tail via influence estimation](https://proceedings.neurips.cc/paper_files/paper/2020/file/1e14bfe2714193e7af5abc64ecbd6b46-Paper.pdf)
- [Do SSL Models Have Déjà Vu? A Case of Unintended Memorization in Self-supervised Learning](https://arxiv.org/pdf/2304.13850.pdf)
 
### Privacy Attacks
- [Membership inference attacks against machine learning models](https://ieeexplore.ieee.org/document/7958568?denied=)
- [Membership inference attacks from first principles](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9833649&casa_token=tAoZzw7Aq7kAAAAA:xq9cagObXSykYl_sw6UiNMQCrYYq_z9gJMKtnaZy5CoaBpe3SNqTco-BDpAIL24A8sUBrwrC)
- [Extracting training data from diffusion models](https://www.usenix.org/system/files/usenixsecurity23-carlini.pdf)
- [Privacy Side Channels in Machine Learning Systems](https://arxiv.org/pdf/2309.05610.pdf)

## Reference:
- [F, Boenisch, J, Vreeken: CISPA - Differential Privacy: Mathematical Foundations and Applications in Machine Learning](https://cms.cispa.saarland/dp_in_ml/)
